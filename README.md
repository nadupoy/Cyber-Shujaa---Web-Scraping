# Cyber Shujaa - Web Scraping

This is my updated solution to the week 1 assignment in the Cyber Shujaa program 
for the Data and AI Specialist track.

## Table of contents

- [Overview](#overview)
  - [The assignment](#the-assignment)
  - [Links](#links)
- [My process](#my-process)
  - [Built with](#built-with)
  - [What I learned](#what-i-learned)
  - [Continued development](#continued-development)
  - [Useful resources](#useful-resources)
- [Author](#author)

## Overview

### The assignment

The goal of the assignment was to develop hands-on experience gathering web data 
using Python.

The objectives were:
  1. Practical Python coding
  2. Data extraction from a web page
  3. Parsing and cleaning the extracted data
  4. Storing structured data into a Pandas DataFrame
  5. Export the final dataset into a .csv file

### Links

- [Google Colab](https://colab.research.google.com/drive/1plbhwdRXuqQXqgncfocjvGL6ntMn_eVj?usp=sharing) 
assignment submission

## My process

### Built with

- [Python](https://www.python.org)
- [Requests](https://requests.readthedocs.io/en/latest) HTTP library for Python
- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc) Python 
library for pulling data out of HTML and XML files
- [Pandas](https://pandas.pydata.org/docs/index.html) Python library used for 
working with data sets with functions for cleaning, exploring and manipulating data

### What I learned

### Continued development

### Useful resources

## Author

- LinkedIn - [Grace Sampao](https://www.linkedin.com/in/grace-sampao)
- GitHub - [@nadupoy](https://github.com/nadupoy)
